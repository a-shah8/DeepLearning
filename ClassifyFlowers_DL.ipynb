{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X39Am9G3m_0Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3Koq60mnRmB",
    "outputId": "1cb9e4ae-f503-433e-8ba1-a61ac58c03e8"
   },
   "outputs": [],
   "source": [
    "### Login to your google account and,\n",
    "## From tensorflow website download the flower_photos.tgz dataset\n",
    "\n",
    "def get_dataset():\n",
    "    _URL = \"# tensorflow dataset link/flower_photos.tgz\"\n",
    "    zip_file = tf.keras.utils.get_file(origin=_URL, fname=\"flower_photos.tgz\", extract=True)\n",
    "    base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')\n",
    "    \n",
    "    return base_dir\n",
    "\n",
    "base_dir = get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the classes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOKG68aRnUSv"
   },
   "outputs": [],
   "source": [
    "classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the train and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCFaVM3wnU8d",
    "outputId": "3d202eb0-cf99-4919-a431-f811683ce0e9"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(base_dir):\n",
    "    \n",
    "    global classes\n",
    "    for _class in classes:\n",
    "        img_path = os.path.join(base_dir, _class)\n",
    "        images = glob.glob(img_path + '/*.jpg')\n",
    "        print(\"{}: {} Images\".format(_class, len(images)))\n",
    "        train, val = images[:round(len(images)*0.8)], images[round(len(images)*0.8):]\n",
    "\n",
    "        for t in train:\n",
    "            if not os.path.exists(os.path.join(base_dir, 'train', _class)):\n",
    "                os.makedirs(os.path.join(base_dir, 'train', _class))\n",
    "            shutil.move(t, os.path.join(base_dir, 'train', _class))\n",
    "        for v in val:\n",
    "            if not os.path.exists(os.path.join(base_dir, 'val', _class)):\n",
    "                os.makedirs(os.path.join(base_dir, 'val', _class))\n",
    "            shutil.move(v, os.path.join(base_dir, 'val', _class))\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quacIKnbnaAh"
   },
   "outputs": [],
   "source": [
    "train, val = prepare_dataset(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator for Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBNusMs1neY4",
    "outputId": "0dcfc1e4-26cf-4964-eb45-c89e820cb22c"
   },
   "outputs": [],
   "source": [
    "img_shape = 150\n",
    "\n",
    "def define_image_generators(train_dir, val_dir):\n",
    "    \n",
    "    global img_shape, batch_size\n",
    "    \n",
    "    image_gen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        rotation_range=45, \n",
    "        zoom_range=0.5, \n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15, \n",
    "        horizontal_flip=True)\n",
    "\n",
    "    train_data_gen = image_gen.flow_from_directory(\n",
    "        batch_size=batch_size, \n",
    "        directory=train_dir, \n",
    "        shuffle=True, \n",
    "        target_size=(img_shape,img_shape), \n",
    "        class_mode='categorical')\n",
    "\n",
    "    image_gen_val = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "    \n",
    "    val_data_gen = image_gen_val.flow_from_directory(\n",
    "        batch_size=batch_size, \n",
    "        directory=val_dir, \n",
    "        shuffle=False, \n",
    "        target_size=(img_shape,img_shape), \n",
    "        class_mode='categorical')\n",
    "    \n",
    "    return train_data_gen, val_data_gen\n",
    "\n",
    "train_data_gen, val_data_gen = define_image_generators(train_dir, val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uP2NC-JcnmCq"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(150, 150, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    global learning_rate\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6tb268Wnt12",
    "outputId": "78492a26-fc74-4796-d276-e85370be8b00"
   },
   "outputs": [],
   "source": [
    "epochs = # no. of epochs to train the model for\n",
    "batch_size = 32\n",
    "\n",
    "def train_model(train_data_gen, val_data_gen):\n",
    "    \n",
    "    global epochs, batch_size\n",
    "    \n",
    "    model = create_model()\n",
    "    history = model.fit(train_data_gen, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batch_size, \n",
    "                        validation_data=val_data_gen)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved Validation Accuracy: 79.32%, (low but hard to improve upon using simple architectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using more sophisticated architectures if more compute resources are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_model(train_data_gen, val_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Accuracy and Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "hSo94Yw-nv1P",
    "outputId": "ec2aa189-bd58-4972-ee7a-a6cbd6a80753"
   },
   "outputs": [],
   "source": [
    "def create_plots(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    global epochs\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "create_plots(history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ClassifyFlowersDL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
